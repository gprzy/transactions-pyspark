{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transactions-pyspark-sql.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulTpzYCEHdYv"
      },
      "source": [
        "# TDE 3 - Big Data Processing with Apache Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9loVTqT0VA-"
      },
      "source": [
        "## Imports & Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6ey7id17vAO",
        "outputId": "088acee5-77aa-4b12-8afe-bc160afe82f7"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfaxyJD6HjBv"
      },
      "source": [
        "import pyspark\n",
        "from pyspark import SparkFiles\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# SparkSQL\n",
        "import pyspark.sql.functions as f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqJifRXTgfSc"
      },
      "source": [
        "## Coletando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgON_gvVgXzo",
        "outputId": "d1cd4a6e-1671-41e6-d777-09f56715fe21"
      },
      "source": [
        "!wget -nc 'http://www.ppgia.pucpr.br/~jean.barddal/bigdata/transactions.csv.zip'\n",
        "!unzip -n transactions.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘transactions.csv.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  transactions.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1j7_bKH1Hy0"
      },
      "source": [
        "## Iniciando a sessão `spark`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZDkRwicMoLw"
      },
      "source": [
        "spark = SparkSession.builder.appName('Transactions').getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3N9XwdqfNJe"
      },
      "source": [
        "## Formato `csv` para SparkSQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STL3CSBEfT97"
      },
      "source": [
        "df = spark.read.csv(\"transactions.csv\", header=True, inferSchema=True, sep=\";\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h90sbpdq20d"
      },
      "source": [
        "# Configuração para realizar consultas com SQL\n",
        "df.createOrReplaceTempView('table')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IuntcOBfisz",
        "outputId": "3811ae98-5a6c-4345-d791-efb033049cb8"
      },
      "source": [
        "# Visualizando as 5 primeiras instâncias\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+----+---------+--------------------+------+---------+---------+---------------+--------+---------------+\n",
            "|country_or_area|year|comm_code|           commodity|  flow|trade_usd|weight_kg|  quantity_name|quantity|       category|\n",
            "+---------------+----+---------+--------------------+------+---------+---------+---------------+--------+---------------+\n",
            "|    Afghanistan|2016|   010410|         Sheep, live|Export|     6088|     2339|Number of items|    51.0|01_live_animals|\n",
            "|    Afghanistan|2016|   010420|         Goats, live|Export|     3958|      984|Number of items|    53.0|01_live_animals|\n",
            "|    Afghanistan|2008|   010210|Bovine animals, l...|Import|  1026804|      272|Number of items|  3769.0|01_live_animals|\n",
            "|        Albania|2016|   010290|Bovine animals, l...|Import|  2414533|  1114023|Number of items|  6853.0|01_live_animals|\n",
            "|        Albania|2016|   010392|Swine, live excep...|Import| 14265937|  9484953|Number of items| 96040.0|01_live_animals|\n",
            "+---------------+----+---------+--------------------+------+---------+---------+---------------+--------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvvYVHvW2wfW"
      },
      "source": [
        "# Using `SparkSQL`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCR0SnPb3DqL"
      },
      "source": [
        "## **1. The number of transactions involving Brazil**;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR2mFs9bhewF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed094995-af36-45fd-8cc2-c15c56acd1ab"
      },
      "source": [
        "# Método 1: Query SQL\n",
        "\n",
        "query_ex1 = \"\"\" SELECT COUNT(country_or_area)\n",
        "                FROM table \n",
        "                WHERE country_or_area = \"Brazil\" \"\"\"\n",
        "\n",
        "# Executando a Query\n",
        "df_trans_brazil_1 = spark.sql(query_ex1)\n",
        "\n",
        "# Exibindo o resultado\n",
        "df_trans_brazil_1.show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+\n",
            "|count(country_or_area)|\n",
            "+----------------------+\n",
            "|                184748|\n",
            "+----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YcGrT5yg-wL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44cb6600-11df-48ea-f9de-22012e2c080b"
      },
      "source": [
        "# Método 2: Maneira Clássica de usar o SparkSQL\n",
        "\n",
        "select_brazil = df.select(f.col('country_or_area')) \n",
        "select_brazil[select_brazil['country_or_area'] == 'Brazil'].count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "184748"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiS3l_RW3F7L"
      },
      "source": [
        "## **2. The number of transactions per year**;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAQ1gFvltq0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030fafd4-89d3-4d08-b089-8575a997ffca"
      },
      "source": [
        "# Método 1: Query SQL\n",
        "\n",
        "query_ex2 = \"\"\" SELECT COUNT(year), year\n",
        "                FROM table\n",
        "                GROUP BY year\n",
        "                ORDER BY year ASC \"\"\"\n",
        "\n",
        "# Executando a Query\n",
        "df_trans_per_year = spark.sql(query_ex2)\n",
        "\n",
        "# Exibindo 29 instâncias iniciais\n",
        "df_trans_per_year.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+----+\n",
            "|count(year)|year|\n",
            "+-----------+----+\n",
            "|      30994|1988|\n",
            "|      63921|1989|\n",
            "|      72258|1990|\n",
            "|      83933|1991|\n",
            "|     121184|1992|\n",
            "+-----------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYtY_wg93MeK"
      },
      "source": [
        "## **3. The most commercialized commodity (summing the quantities) in 2016, per flow type**;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oVLcLMVuIgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f43cb43-efcb-4a79-87e7-17eea042da59"
      },
      "source": [
        "# Método 1: Query SQL\n",
        "\n",
        "query_ex3 = \"\"\" SELECT commodity, flow, sum_comm from(\n",
        "                    SELECT flow, sum_comm, ROW_NUMBER() OVER (PARTITION BY flow ORDER BY sum_comm DESC) rn, commodity \n",
        "                        FROM (SELECT SUM(weight_kg) AS sum_comm, flow, commodity\n",
        "                                    FROM table \n",
        "                                    WHERE year = 2016 and comm_code <> 'TOTAL' AND weight_kg IS NOT NULL\n",
        "                                    GROUP BY flow, commodity)\n",
        "                        GROUP BY flow, sum_comm, commodity) WHERE rn = 1 \n",
        "                        ORDER BY sum_comm \"\"\"\n",
        "\n",
        "# Executando a Query\n",
        "df_mc_comm_2016_flowtype = spark.sql(query_ex3)\n",
        "\n",
        "# Exibindo 29 instâncias iniciais\n",
        "df_mc_comm_2016_flowtype.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+---------+-------------+\n",
            "|           commodity|     flow|     sum_comm|\n",
            "+--------------------+---------+-------------+\n",
            "|Lumber, coniferou...|Re-Import|     51951285|\n",
            "|Oils petroleum, b...|Re-Export|   1452933784|\n",
            "|Iron ore, concent...|   Export|1343444789618|\n",
            "|Iron ore, concent...|   Import|1362436716054|\n",
            "+--------------------+---------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McoXCS_a3OdU"
      },
      "source": [
        "## **4. The average of commodity values per year**;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtJwuj-_v4gi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57de1b2-91f4-4c66-f40c-216317e96aa5"
      },
      "source": [
        "# Método 1: Query SQL\n",
        "\n",
        "query_ex4 = \"\"\" SELECT AVG(trade_usd) AS avgCommValues, year\n",
        "                FROM table\n",
        "                WHERE comm_code <> 'TOTAL'\n",
        "                GROUP BY year\n",
        "                ORDER BY year ASC \"\"\"\n",
        "\n",
        "# Executando a Query\n",
        "df_avg_comm_values_year = spark.sql(query_ex4)\n",
        "\n",
        "# Exibindo 29 instâncias iniciais\n",
        "df_avg_comm_values_year.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+\n",
            "|       avgCommValues|year|\n",
            "+--------------------+----+\n",
            "|1.4906524119341299E7|1988|\n",
            "| 1.265845836696156E7|1989|\n",
            "| 1.293112022652722E7|1990|\n",
            "| 1.295085407263576E7|1991|\n",
            "|1.1579386262822261E7|1992|\n",
            "+--------------------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqHf5kkl3Ols"
      },
      "source": [
        "## **5. The average price of commodities per unit type, year, and category in the export flow in Brazil**;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFo3YjkXwnOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffb86a2-8735-4f4a-9132-05ba6ea2c072"
      },
      "source": [
        "# Método 1: Query SQL\n",
        "\n",
        "query_ex5 = \"\"\" SELECT AVG(trade_usd) AS avgCommValues, quantity_name, year, category\n",
        "                FROM table\n",
        "                WHERE \n",
        "                      flow = 'Export' \n",
        "                  AND comm_code <> 'TOTAL' \n",
        "                  AND country_or_area = 'Brazil' \n",
        "                  AND category is not null \n",
        "                  AND trade_usd is not null\n",
        "                GROUP BY quantity_name, year, category\n",
        "                ORDER BY year, category ASC \"\"\"\n",
        "\n",
        "# Executando a Query\n",
        "df_avg_comm_values_unittype_year_cat_expflow_brazil = spark.sql(query_ex5)\n",
        "\n",
        "# Exibindo 29 instâncias iniciais\n",
        "df_avg_comm_values_unittype_year_cat_expflow_brazil.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-------------------+----+--------------------+\n",
            "|    avgCommValues|      quantity_name|year|            category|\n",
            "+-----------------+-------------------+----+--------------------+\n",
            "|         351970.2|Weight in kilograms|1989|     01_live_animals|\n",
            "| 1.454414546875E7|Weight in kilograms|1989|02_meat_and_edibl...|\n",
            "|        3150434.7|Weight in kilograms|1989|03_fish_crustacea...|\n",
            "|760340.3333333334|    Number of items|1989|04_dairy_products...|\n",
            "|59596.57142857143|Weight in kilograms|1989|04_dairy_products...|\n",
            "+-----------------+-------------------+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37LA08N03OtW"
      },
      "source": [
        "## **6. The commodity with the highest price per unit type and year**;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur-89UocgbsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a352ac-2335-4ec3-b50d-d579a93662fd"
      },
      "source": [
        "# Método 1: Query SQL\n",
        "\n",
        "query_ex6 = \"\"\" SELECT MAX(trade_usd), quantity_name, year\n",
        "                FROM table\n",
        "                GROUP BY quantity_name, year \n",
        "                ORDER BY quantity_name, year ASC \"\"\"\n",
        "\n",
        "# Executando a Query\n",
        "df_comm_hp_unittype_year_1 = spark.sql(query_ex6)\n",
        "\n",
        "# Exibindo 29 instâncias iniciais\n",
        "df_comm_hp_unittype_year_1.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+--------------------+----+\n",
            "|max(trade_usd)|       quantity_name|year|\n",
            "+--------------+--------------------+----+\n",
            "|     403386005|Area in square me...|1988|\n",
            "|     367370724|Area in square me...|1989|\n",
            "|     347716597|Area in square me...|1990|\n",
            "|     403965643|Area in square me...|1991|\n",
            "|     323730149|Area in square me...|1992|\n",
            "+--------------+--------------------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_iEkR013O1F"
      },
      "source": [
        "## **7. The number of transactions per flow type and year**;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enP25BEM3Ikx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b8f2ccf-d722-42d0-8eeb-50ab4e84b561"
      },
      "source": [
        "# Método 1: Query SQL\n",
        "\n",
        "query_ex7 = \"\"\" SELECT COUNT(flow) AS noTransactions, flow, year\n",
        "                FROM table\n",
        "                GROUP BY flow, year \n",
        "                ORDER BY flow, year ASC \"\"\"\n",
        "\n",
        "# Executando a Query\n",
        "no_trans_flowtype_year_1 = spark.sql(query_ex7)\n",
        "\n",
        "# Exibindo 29 instâncias iniciais\n",
        "no_trans_flowtype_year_1.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+------+----+\n",
            "|noTransactions|  flow|year|\n",
            "+--------------+------+----+\n",
            "|         12510|Export|1988|\n",
            "|         26166|Export|1989|\n",
            "|         29170|Export|1990|\n",
            "|         32847|Export|1991|\n",
            "|         45810|Export|1992|\n",
            "+--------------+------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}